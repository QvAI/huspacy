title: "Part-of-speech Tagging, Lemmatization & Dependency Parsing (Universal Dependencies)"
description: ""
spacy_version: ">=3.1.0,<3.2.0"

vars:
  lang: hu
  # The convention is to use the format: modeltype_preferreddomain_modelsize
  core_package_name: core_news_lg
  # Wrokaround: spacy project yaml cannot interpolate variables inside the `vars` sections
  package_name: hu_core_news_lg
  package_version: 0.1.0

  models_path: ../models
  packages_path: ../packages

  raw_data_path: ../data/raw
  processed_data_path: ../data/processed
  external_data_path: ../data/external

  treebank: UD_Hungarian-Szeged
  train_name: hu_szeged-ud-train
  dev_name: hu_szeged-ud-dev
  test_name: hu_szeged-ud-test
  nerkor: NerKor
  szegedcorpus: SzegedCorpus

  wandb_entity: spacy-hu
  wandb_project: hu_core_news_lg

  parser_config: parser
  ner_config: ner
  gpu: -1

#TODO: remove GPU settings
#TODO: remove WAND options settings
#TODO: provide examples for WANDB and GPU settings

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: [configs, ../models, ../packages, ../data/raw, ../data/processed, ../data/external]

assets:
  - dest: ${vars.raw_data_path}/${vars.treebank}
    git:
      repo: https://github.com/UniversalDependencies/${vars.treebank}
      branch: master
      path: ""

  - dest: ${vars.raw_data_path}/${vars.nerkor}
    git:
      repo: https://github.com/oroszgy/NYTK-NerKor
      branch: dev
      path: data

  - dest: ${vars.external_data_path}/webcorpuswiki.word2vec.bz2
    url: https://github.com/oroszgy/hunlp-resources/releases/download/webcorpuswiki_word2vec_v0.1/webcorpuswiki.word2vec.bz2

  - dest: ${vars.raw_data_path}/${vars.szegedcorpus}/${vars.szegedcorpus}.zip
    url: http://www.inf.u-szeged.hu/~szantozs/download/ud_converted/univmorph.hu.zip
    checksum: 55768c77029b0e0f0bf10afd906e20a7

workflows:
  all:
    - convert_vectors
    - preprocess_ud
    - preprocess_nerkor
    - preprocess_szegedcorpus
    - train_lemmatizer
    - train_parser
    - train_ner
    - evaluate
    - package
    - push

commands:
  - name: convert_vectors
    help: "Convert vectors"

    script:
      - "bash -c '/bin/bzcat ${vars.external_data_path}/webcorpuswiki.word2vec.bz2
          > ${vars.external_data_path}/webcorpuswiki.word2vec.txt'"
      - "python -m spacy init vectors hu ${vars.external_data_path}/webcorpuswiki.word2vec.txt
          ${vars.external_data_path}/webcorpuswiki.word2vec.vec"
    deps:
      - ${vars.external_data_path}/webcorpuswiki.word2vec.bz2
    outputs:
      - ${vars.external_data_path}/webcorpuswiki.word2vec.vec

  - name: preprocess_ud
    help: "Convert the UD corpus to spaCy's format"
    script:
      - "mkdir -p ${vars.processed_data_path}/${vars.treebank}"
      - "python -m spacy convert ${vars.raw_data_path}/${vars.treebank}/${vars.train_name}.conllu
          ${vars.processed_data_path}/${vars.treebank}/ --converter conllu --n-sents 10 --merge-subtokens"
      - "python -m spacy convert ${vars.raw_data_path}/${vars.treebank}/${vars.dev_name}.conllu
          ${vars.processed_data_path}/${vars.treebank}/ --converter conllu --n-sents 10 --merge-subtokens"
      - "python -m spacy convert ${vars.raw_data_path}/${vars.treebank}/${vars.test_name}.conllu
          ${vars.processed_data_path}/${vars.treebank}/ --converter conllu --n-sents 10 --merge-subtokens"
      - "mv ${vars.processed_data_path}/${vars.treebank}/${vars.train_name}.spacy
          ${vars.processed_data_path}/${vars.treebank}/train.spacy"
      - "mv ${vars.processed_data_path}/${vars.treebank}/${vars.dev_name}.spacy
          ${vars.processed_data_path}/${vars.treebank}/dev.spacy"
      - "mv ${vars.processed_data_path}/${vars.treebank}/${vars.test_name}.spacy
          ${vars.processed_data_path}/${vars.treebank}/test.spacy"
    deps:
      - ${vars.raw_data_path}/${vars.treebank}/${vars.train_name}.conllu
      - ${vars.raw_data_path}/${vars.treebank}/${vars.dev_name}.conllu
      - ${vars.raw_data_path}/${vars.treebank}/${vars.test_name}.conllu
    outputs:
      - ${vars.processed_data_path}/${vars.treebank}/train.spacy
      - ${vars.processed_data_path}/${vars.treebank}/dev.spacy
      - ${vars.processed_data_path}/${vars.treebank}/test.spacy

  - name: preprocess_nerkor
    help: "Convert the UD corpus to spaCy's format"
    script:
      - "mkdir -p ${vars.processed_data_path}/${vars.nerkor}"
      - "convert2conllu '${vars.raw_data_path}/${vars.nerkor}/train-devel-test/devel/*/morph/*.conllup'
          ${vars.processed_data_path}/${vars.nerkor}/dev.conllup"
      - "convert2conllu '${vars.raw_data_path}/${vars.nerkor}/train-devel-test/train/*/morph/*.conllup'
          ${vars.processed_data_path}/${vars.nerkor}/train.conllup"
      - "convert2conllu '${vars.raw_data_path}/${vars.nerkor}/train-devel-test/test/*/morph/*.conllup'
          ${vars.processed_data_path}/${vars.nerkor}/test.conllup"

      - python -m spacy convert ${vars.processed_data_path}/${vars.nerkor}/train.conllup ${vars.processed_data_path}/${vars.nerkor} --converter conllu --n-sents 10
      - python -m spacy convert ${vars.processed_data_path}/${vars.nerkor}/dev.conllup ${vars.processed_data_path}/${vars.nerkor} --converter conllu --n-sents 10
      - python -m spacy convert ${vars.processed_data_path}/${vars.nerkor}/test.conllup ${vars.processed_data_path}/${vars.nerkor} --converter conllu --n-sents 10
    deps:
      - ${vars.raw_data_path}/${vars.nerkor}
    outputs:
      - ${vars.processed_data_path}/${vars.nerkor}/train.conllup
      - ${vars.processed_data_path}/${vars.nerkor}/dev.conllup
      - ${vars.processed_data_path}/${vars.nerkor}/test.conllup
      - ${vars.processed_data_path}/${vars.nerkor}/train.spacy
      - ${vars.processed_data_path}/${vars.nerkor}/dev.spacy
      - ${vars.processed_data_path}/${vars.nerkor}/test.spacy

  - name: preprocess_szegedcorpus
    help: "Convert the Szeged corpus to dev/test/train and spaCy's format"
    script:
      - "mkdir -p ${vars.processed_data_path}/${vars.szegedcorpus}"
      - "unzip -o ${vars.raw_data_path}/${vars.szegedcorpus}/${vars.szegedcorpus}.zip -d ${vars.raw_data_path}/${vars.szegedcorpus}/zip/"
      - "split-conllu '${vars.raw_data_path}/${vars.szegedcorpus}/zip/*.conllu' '${vars.raw_data_path}/${vars.treebank}/*.conllu' ${vars.processed_data_path}/${vars.szegedcorpus}/"

      - python -m spacy convert ${vars.processed_data_path}/${vars.szegedcorpus}/train.conllu ${vars.processed_data_path}/${vars.szegedcorpus} --converter conllu --n-sents 10
      - python -m spacy convert ${vars.processed_data_path}/${vars.szegedcorpus}/dev.conllu ${vars.processed_data_path}/${vars.szegedcorpus} --converter conllu --n-sents 10
      - python -m spacy convert ${vars.processed_data_path}/${vars.szegedcorpus}/test.conllu ${vars.processed_data_path}/${vars.szegedcorpus} --converter conllu --n-sents 10
    deps:
      - ${vars.raw_data_path}/${vars.szegedcorpus}
      - ${vars.raw_data_path}/${vars.treebank}/${vars.train_name}.conllu
      - ${vars.raw_data_path}/${vars.treebank}/${vars.dev_name}.conllu
      - ${vars.raw_data_path}/${vars.treebank}/${vars.test_name}.conllu
    outputs:
      - ${vars.processed_data_path}/${vars.szegedcorpus}/train.conllup
      - ${vars.processed_data_path}/${vars.szegedcorpus}/dev.conllup
      - ${vars.processed_data_path}/${vars.szegedcorpus}/test.conllup
      - ${vars.processed_data_path}/${vars.szegedcorpus}/train.spacy
      - ${vars.processed_data_path}/${vars.szegedcorpus}/dev.spacy
      - ${vars.processed_data_path}/${vars.szegedcorpus}/test.spacy

  - name: train_lemmatizer
    help: "Train the lemmatizer"
    script:
      - "lemmy train ${vars.processed_data_path}/${vars.nerkor}/train.conllup ${vars.models_path}/lemmy-${vars.package_version}.bin"
      - "lemmy evaluate ${vars.models_path}/lemmy-${vars.package_version}.bin ${vars.processed_data_path}/${vars.nerkor}/test.conllup"
      - "lemmy evaluate ${vars.models_path}/lemmy-${vars.package_version}.bin ${vars.raw_data_path}/${vars.treebank}/${vars.test_name}.conllu"
    deps:
      - ${vars.processed_data_path}/${vars.nerkor}/train.conllup
      - ${vars.processed_data_path}/${vars.nerkor}/test.conllup
      - ${vars.raw_data_path}/${vars.treebank}/${vars.test_name}.conllu
    outputs:
      - ${vars.models_path}/lemmy-${vars.package_version}.bin

  - name: train_parser
    help: "Train the parser/tagger"
    script:
      - "bash -c 'WANDB_ENTITY=${vars.wandb_entity} WANDB_PROJECT=${vars.wandb_project}
          python -m spacy train configs/${vars.parser_config}.cfg
            --output ${vars.models_path}/${vars.package_name}-${vars.package_version}
            --gpu-id ${vars.gpu} --nlp.lang=${vars.lang}
            --paths.vectors ${vars.external_data_path}/webcorpuswiki.word2vec.vec
            --paths.train ${vars.processed_data_path}/${vars.treebank}/train.spacy
            --paths.dev ${vars.processed_data_path}/${vars.treebank}/dev.spacy'"
    deps:
      - ${vars.processed_data_path}/${vars.treebank}/train.spacy
      - ${vars.processed_data_path}/${vars.treebank}/dev.spacy
      - configs/${vars.parser_config}.cfg
    outputs:
      - ${vars.models_path}/${vars.package_name}-${vars.package_version}/model-best

  - name: train_ner
    help: "Train the NER model"
    script:
      - "python -m spacy train configs/${vars.ner_config}.cfg
          --output ${vars.models_path}/${vars.package_name}-ner-${vars.package_version}
          --nlp.lang=${vars.lang} --gpu-id ${vars.gpu}
          --paths.vectors ${vars.external_data_path}/webcorpuswiki.word2vec.vec
          --paths.train ${vars.processed_data_path}/${vars.nerkor}/train.spacy
          --paths.dev ${vars.processed_data_path}/${vars.nerkor}/dev.spacy"
    deps:
      - ${vars.processed_data_path}/${vars.nerkor}/train.spacy
      - ${vars.processed_data_path}/${vars.nerkor}/dev.spacy
      - ${vars.processed_data_path}/${vars.nerkor}/test.spacy
    outputs:
      - ${vars.models_path}/${vars.package_name}-ner-${vars.package_version}/model-best

  - name: evaluate
    help: "Evaluate on the test data and save the metrics"
    script:
      - "python -m spacy evaluate
          ${vars.models_path}/${vars.package_name}-${vars.package_version}/model-best
          ${vars.processed_data_path}/${vars.treebank}/test.spacy
          --output ${vars.models_path}/${vars.package_name}-${vars.package_version}.json --gpu-id ${vars.gpu} -G"
    deps:
      - ${vars.models_path}/${vars.package_name}-${vars.package_version}/model-best
      - ${vars.processed_data_path}/${vars.treebank}/test.spacy
    outputs:
      - "metrics/${vars.treebank}.json"

  - name: package
    help: "Package the trained model so it can be installed"
    script:
      - "python -m spacy package
          ${vars.models_path}/${vars.package_name}-${vars.package_version}/model-best ${vars.packages_path}
          --build 'sdist, wheel'
          --name ${vars.core_package_name}
          --version ${vars.package_version}
          --force"
    deps:
      -  ${vars.models_path}/${vars.package_name}-${vars.package_version}/model-best
    outputs_no_cache:
      - ${vars.packages_path}/${vars.package_name}-${vars.package_version}/dist/en_${vars.package_name}-${vars.package_version}.tar.gz
      - ${vars.packages_path}/${vars.package_name}-${vars.package_version}/dist/en_${vars.package_name}-${vars.package_version}-py3-none-any.whl

  - name: push
    help: "Upload the trained model to the Hugging Face Hub"
    script:
      - "python -m spacy huggingface-hub push
          ${vars.packages_path}/${vars.package_name}-${vars.package_version}/dist/${vars.package_name}-${vars.package_version}-py3-none-any.whl"
    deps:
      - ${vars.packages_path}/${vars.package_name}-${vars.package_version}/dist/${vars.package_name}-${vars.package_version}-py3-none-any.whl

  - name: clean
    help: "Remove intermediate files"
    script:
      - "rm -rf ${vars.processed_data_path}"
      - "rm -rf ${vars.models_path}"
