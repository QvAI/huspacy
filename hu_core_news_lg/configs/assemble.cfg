[paths]
parser_model = "../models/hu_core_news_lg-parser-0.1.0/model-best"
ner_model = "../models/hu_core_news_lg-ner-0.1.0/model-best"

#TODO: add lemmatizer and sentencizer

[nlp]
lang = "hu"
pipeline = ["tok2vec", "hun_sentencizer", "tagger", "morphologizer", "parser", "ner"]
tokenizer = {"@tokenizers":"spacy.Tokenizer.v1"}

[initialize]
vectors = ${paths.parser_model}

[components]

[components.tok2vec]
source = ${paths.parser_model}
component = "tok2vec"

[components.hun_sentencizer]
factory = "hun_sentencizer"

[components.tagger]
source = ${paths.parser_model}
component = "tagger"

[components.morphologizer]
source = ${paths.parser_model}
component = "morphologizer"

[components.parser]
source = ${paths.parser_model}
component = "parser"

[components.ner]
source = ${paths.ner_model}
component = "ner"
# TODO: this might not be needed
# This model needs to use the tok2vec it was originally trained with
replace_listeners = ["model.tok2vec"]
