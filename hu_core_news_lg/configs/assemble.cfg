[paths]
parser_model = null
lemmy_model = null
ner_model = null
edit_tree_lemmatizer_model = null

[nlp]
lang = "hu"
#pipeline = ["tok2vec", "senter", "tagger", "morphologizer", "lemmatizer","parser", "ner"]
pipeline = ["tok2vec", "senter", "tagger", "morphologizer", "lemmatizer", "parser"]
tokenizer = {"@tokenizers":"spacy.Tokenizer.v1"}

[initialize]
vectors = ${paths.parser_model}
#components = {"lemmatizer": {"model_path": "${paths.lemmy_model}"}}

[components]

[components.lemmatizer]
source = ${paths.edit_tree_lemmatizer_model}
component = "experimental_edit_tree_lemmatizer"
replace_listeners = ["model.tok2vec"]

[components.tok2vec]
source = ${paths.parser_model}
component = "tok2vec"

[components.senter]
source = ${paths.parser_model}
component = "senter"
;[components.hun_sentencizer]
;factory = "hun_sentencizer"

[components.tagger]
source = ${paths.parser_model}
component = "tagger"

[components.morphologizer]
source = ${paths.parser_model}
component = "morphologizer"

# [components.lemmatizer]
# factory = "hu.lemmatizer"


[components.parser]
source = ${paths.parser_model}
component = "parser"

# [components.ner]
# source = ${paths.ner_model}
# component = "ner"
# # TODO: this might not be needed
# # This model needs to use the tok2vec it was originally trained with
# replace_listeners = ["model.tok2vec"]
